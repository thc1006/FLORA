{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thc1006/FLORA/blob/main/0630_FLORA_client_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 1: ç’°å¢ƒè¨­å®šèˆ‡å‡½å¼åº«åŒ¯å…¥ï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
        "!pip install --upgrade opacus -q\n",
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np, pandas as pd, random, copy, json, os, time, warnings, math, re, contextlib\n",
        "from collections import deque\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from dataclasses import dataclass, asdict\n",
        "from sklearn.cluster import KMeans\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "from opacus.data_loader import DPDataLoader\n",
        "\n",
        "# --- ç’°å¢ƒè¨­å®š ---\n",
        "try: torch._dynamo.disable()\n",
        "except Exception: pass\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=\".*overflow encountered.*\", category=RuntimeWarning)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "print(\"âœ… Cell 1: ç’°å¢ƒèˆ‡å‡½å¼åº«æº–å‚™å°±ç·’ã€‚\")\n",
        "import opacus\n",
        "print(f\"PyTorch/Opacus ç‰ˆæœ¬: {torch.__version__} / {opacus.__version__}\")\n",
        "print(f\"CUDA æ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "jWyXJ3F_H9G-",
        "outputId": "6778310b-4600-4a27-b506-9e5bb8b3f5a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Cell 1: ç’°å¢ƒèˆ‡å‡½å¼åº«æº–å‚™å°±ç·’ã€‚\n",
            "PyTorch/Opacus ç‰ˆæœ¬: 2.6.0+cu124 / 1.5.4\n",
            "CUDA æ˜¯å¦å¯ç”¨: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 2: ğŸ“ å¯¦é©—åƒæ•¸è¨­å®šï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    experiment_name: str; output_dir: str\n",
        "    mode: str = \"ClusteredFL\"\n",
        "    random_seed: int = 42\n",
        "    comm_rounds: int = 25\n",
        "    client_pairs: tuple = ((1, 2), (3, 7), (5, 6))\n",
        "    num_clients: int = 3\n",
        "    num_clients_to_select: int = 3\n",
        "\n",
        "    local_episodes_per_round: int = 10\n",
        "    steps_per_episode: int = 500; batch_size: int = 64\n",
        "    gamma: float = 0.99\n",
        "\n",
        "    # --- ç©©å®šæ€§åƒæ•¸ ---\n",
        "    lr: float = 1e-4\n",
        "    target_update_freq: int = 10\n",
        "\n",
        "    # --- RL æ¢ç´¢åƒæ•¸ ---\n",
        "    epsilon_start: float = 1.0; epsilon_decay: float = 0.9995; epsilon_min: float = 0.05\n",
        "\n",
        "    # --- è¨˜æ†¶èˆ‡å›æ”¾ ---\n",
        "    memory_capacity: int = 50000\n",
        "    replay_start_size: int = 1000\n",
        "    replay_frequency: int = 4\n",
        "    replay_batches_per_call: int = 1\n",
        "\n",
        "    # --- è¯é‚¦å­¸ç¿’ç­–ç•¥åƒæ•¸ ---\n",
        "    fedprox_mu: float = 0.01\n",
        "    num_clusters: int = 2  # ä¿®æ­£ï¼šæ¸›å°‘ç‚º2å€‹èšé¡ä»¥æé«˜ç©©å®šæ€§\n",
        "    cluster_update_freq: int = 15\n",
        "\n",
        "    # --- åŠŸèƒ½é–‹é—œï¼ˆä¿®æ­£ç‰ˆï¼‰---\n",
        "    enable_dp: bool = False  # ä¿®æ­£ï¼šæš«æ™‚ç¦ç”¨å·®åˆ†éš±ç§ä»¥ç¢ºä¿ç©©å®šæ€§\n",
        "    enable_heterogeneity: bool = True\n",
        "    enable_compression: bool = True\n",
        "\n",
        "    # --- DP åƒæ•¸ï¼ˆä¿ç•™ä½†ä¸ä½¿ç”¨ï¼‰---\n",
        "    dp_target_epsilon: float = 8.0\n",
        "    dp_target_delta: float = 1e-5\n",
        "    dp_max_grad_norm: float = 1.0\n",
        "    dp_noise_multiplier: float = 1.2\n",
        "    dp_sample_rate: float = 0.02\n",
        "\n",
        "    # --- ç³»çµ±è¨­å®š ---\n",
        "    straggler_ratio: float = 0.2; dropout_ratio: float = 0.1\n",
        "    compression_type: str = \"quantize_fp16\"\n",
        "    use_pfl_finetune: bool = True; local_finetune_episodes: int = 25\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    reset_to_random_start: bool = True\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.mode == 'Centralized' or self.mode == 'Isolated':\n",
        "            self.enable_heterogeneity = False\n",
        "            self.enable_compression = False\n",
        "            self.fedprox_mu = 0\n",
        "            print(f\"ğŸ§ª æ¨¡å¼ '{self.mode}' ä¸­ï¼Œç•°è³ªæ€§ã€å£“ç¸®ã€FedProx å°‡è¢«ç¦ç”¨ã€‚\")\n",
        "        if self.mode not in ['FedProx', 'ClusteredFL']:\n",
        "            self.fedprox_mu = 0\n",
        "        if self.mode == 'Centralized':\n",
        "            self.enable_dp = False\n",
        "            print(f\"ğŸ›¡ï¸ æ¨¡å¼ 'Centralized' ä¸­ï¼Œå·®åˆ†éš±ç§å·²è¢«ç¦ç”¨ä»¥ä½œç‚ºééš±ç§åŸºæº–ã€‚\")\n",
        "\n",
        "        # ä¿®æ­£ï¼šæš«æ™‚å…¨é¢ç¦ç”¨å·®åˆ†éš±ç§\n",
        "        if self.enable_dp:\n",
        "            print(f\"âš ï¸  å·®åˆ†éš±ç§èˆ‡å¼·åŒ–å­¸ç¿’å­˜åœ¨å…¼å®¹æ€§å•é¡Œï¼Œæš«æ™‚ç¦ç”¨ä»¥ç¢ºä¿å¯¦é©—ç©©å®šæ€§ã€‚\")\n",
        "            self.enable_dp = False\n",
        "\n",
        "        if self.enable_heterogeneity:\n",
        "            print(f\"ğŸ”€ ç³»çµ±ç•°è³ªæ€§å·²å•Ÿç”¨ (æ‰ç·šç‡: {self.dropout_ratio}, è½å¾Œè€…ç‡: {self.straggler_ratio}).\")\n",
        "        if self.enable_compression:\n",
        "            print(f\"ğŸ“¡ æ¨¡å‹å£“ç¸® ({self.compression_type}) å·²å•Ÿç”¨ã€‚\")\n",
        "        if self.fedprox_mu > 0:\n",
        "            print(f\"ğŸ’ª FedProx (mu={self.fedprox_mu}) å·²å•Ÿç”¨ã€‚\")\n",
        "\n",
        "    def save(self):\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        path = os.path.join(self.output_dir, f'{self.experiment_name}_config.json')\n",
        "        config_dict = {k: (list(v) if isinstance(v, tuple) else v) for k, v in asdict(self).items()}\n",
        "        with open(path, 'w') as f: json.dump(config_dict, f, indent=4)\n",
        "\n",
        "print(\"âœ… Cell 2: TrainingConfigï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Qp11BP-2IANH",
        "outputId": "d0298897-8c10-4405-c873-59b61b7c79b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 2: TrainingConfigï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 3: ğŸ§© æ•¸æ“šèˆ‡ç’°å¢ƒæº–å‚™ï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
        "class DataManager:\n",
        "    def __init__(self, data_path, client_pairs_config):\n",
        "        print(f\"\\n[DataManager] æ­£åœ¨å¾ {data_path} è®€å–æ•¸æ“š...\")\n",
        "        self.df_kpi = pd.read_parquet(data_path)\n",
        "        self.client_pairs_config = client_pairs_config\n",
        "        self._sanitize_column_names(); self._preflight_check()\n",
        "\n",
        "    def _sanitize_column_names(self):\n",
        "        sanitized_columns = [re.sub(r'[\\[\\]\\(\\)%\\s\\.-]+', '_', col.strip().lower()).strip('_')\n",
        "                           for col in self.df_kpi.columns]\n",
        "        self.df_kpi.columns = sanitized_columns\n",
        "\n",
        "    def _preflight_check(self):\n",
        "        print(\"\\n\" + \"=\"*20 + \" DataManager å•Ÿå‹•å‰é æª¢æŸ¥ \" + \"=\"*20)\n",
        "        cols = self.df_kpi.columns.tolist()\n",
        "        tput_cand = ['throughput_dl_mbps', 'tx_brate_downlink_mbps']\n",
        "        lat_cand = ['buffer_occupancy_dl_bytes', 'dl_buffer_bytes']\n",
        "\n",
        "        self.tput_col = next((c for c in tput_cand if c in cols), None)\n",
        "        self.lat_col = next((c for c in lat_cand if c in cols), None)\n",
        "\n",
        "        print(f\"âœ… æ¸…ç†å¾Œçš„æ¬„ä½åˆ—è¡¨ (å…± {len(cols)} å€‹):\")\n",
        "        print(f\"   - ååé‡æ¬„ä½æˆåŠŸåŒ¹é…: '{self.tput_col}'\" if self.tput_col\n",
        "              else \"   - ååé‡æ¬„ä½åŒ¹é…å¤±æ•—ï¼\")\n",
        "        print(f\"   - å»¶é²/ç·©è¡å€æ¬„ä½æˆåŠŸåŒ¹é…: '{self.lat_col}'\" if self.lat_col\n",
        "              else \"   - å»¶é²/ç·©è¡å€æ¬„ä½åŒ¹é…å¤±æ•—ï¼\")\n",
        "\n",
        "        # ä¿®æ­£ï¼šæª¢æŸ¥BSç¯€é»çš„å¯¦éš›å¯ç”¨æ€§\n",
        "        available_bs = sorted(self.df_kpi['bs_id'].unique())\n",
        "        print(f\"   - å¯ç”¨BSç¯€é»: {available_bs}\")\n",
        "\n",
        "        # é©—è­‰å®¢æˆ¶ç«¯é…å°çš„æœ‰æ•ˆæ€§\n",
        "        for i, (embb_bs, urllc_bs) in enumerate(self.client_pairs_config):\n",
        "            if embb_bs not in available_bs or urllc_bs not in available_bs:\n",
        "                raise ValueError(f\"å®¢æˆ¶ç«¯ {i} çš„BSé…å° ({embb_bs}, {urllc_bs}) ä¸­åŒ…å«ä¸å­˜åœ¨çš„BSç¯€é»\")\n",
        "        print(\"   - å®¢æˆ¶ç«¯BSé…å°é©—è­‰é€šé\")\n",
        "        print(\"=\"*65 + \"\\n\")\n",
        "\n",
        "        if not (self.tput_col and self.lat_col):\n",
        "            raise ValueError(\"é æª¢æŸ¥å¤±æ•—: æ‰¾ä¸åˆ°å¿…è¦çš„æ•¸æ“šæ¬„ä½ã€‚\")\n",
        "\n",
        "    def _get_clean_df(self, gnb_id, slice_id):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šå¢åŠ æ›´åš´æ ¼çš„æ•¸æ“šéæ¿¾å’Œé©—è­‰\"\"\"\n",
        "        df, bs_col, sl_col = self.df_kpi, 'bs_id', 'slice_id'\n",
        "\n",
        "        # ç¢ºä¿æ•¸æ“šé¡å‹ä¸€è‡´æ€§\n",
        "        mask = (df[bs_col].astype(int) == int(gnb_id)) & (df[sl_col].astype(int) == int(slice_id))\n",
        "        subset = df.loc[mask, ['timestamp', self.tput_col, self.lat_col]].copy()\n",
        "\n",
        "        # ä¿®æ­£ï¼šæ›´åš´æ ¼çš„æ•¸æ“šæ¸…ç†\n",
        "        subset = subset.rename(columns={self.tput_col: 'throughput', self.lat_col: 'latency'})\n",
        "        subset = subset.dropna()\n",
        "\n",
        "        # ç§»é™¤ç•°å¸¸å€¼ï¼ˆè¶…å‡ºåˆç†ç¯„åœçš„æ•¸æ“šé»ï¼‰\n",
        "        if not subset.empty:\n",
        "            subset = subset[\n",
        "                (subset['throughput'] >= 0) & (subset['throughput'] <= 1000) &  # ååé‡ç¯„åœ\n",
        "                (subset['latency'] >= 0) & (subset['latency'] <= 1e9)  # å»¶é²ç¯„åœ\n",
        "            ]\n",
        "\n",
        "        return subset\n",
        "\n",
        "    def get_client_trajectories(self):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šç¢ºä¿å®¢æˆ¶ç«¯æ•¸æ“šå®Œå…¨ç¨ç«‹\"\"\"\n",
        "        client_trajectories = {}\n",
        "        print(\"[DataManager] æ­£åœ¨ç‚ºæ¯å€‹å®¢æˆ¶ç«¯ç”Ÿæˆæ•¸æ“šè»Œè·¡...\")\n",
        "\n",
        "        for i, (embb_id, urllc_id) in enumerate(tqdm(self.client_pairs_config, desc=\"è™•ç†å®¢æˆ¶ç«¯æ•¸æ“š\")):\n",
        "            try:\n",
        "                # ç¢ºä¿æ¯å€‹å®¢æˆ¶ç«¯ä½¿ç”¨ä¸åŒçš„BSï¼Œç¶­è­·æ•¸æ“šç¨ç«‹æ€§\n",
        "                df_embb = self._get_clean_df(embb_id, 0)  # eMBBåˆ‡ç‰‡\n",
        "                df_urllc = self._get_clean_df(urllc_id, 2)  # URLLCåˆ‡ç‰‡\n",
        "\n",
        "                if df_embb.empty or df_urllc.empty:\n",
        "                    print(f\"ğŸŸ¡ è­¦å‘Š: å®¢æˆ¶ç«¯ {i} (BS {embb_id}/{urllc_id}) ç¯©é¸å¾Œç„¡æœ‰æ•ˆæ•¸æ“šã€‚\")\n",
        "                    client_trajectories[i] = np.array([])\n",
        "                    continue\n",
        "\n",
        "                # ä¿®æ­£ï¼šä½¿ç”¨æ›´ä¿å®ˆçš„æ™‚é–“å®¹å¿åº¦ï¼Œé¿å…æ•¸æ“šæ´©æ¼\n",
        "                merged_df = pd.merge_asof(\n",
        "                    df_embb.sort_values('timestamp'),\n",
        "                    df_urllc.sort_values('timestamp'),\n",
        "                    on='timestamp',\n",
        "                    direction='backward',  # ç¢ºä¿åªä½¿ç”¨éå»çš„ä¿¡æ¯\n",
        "                    tolerance=pd.Timedelta('100ms'),  # æ¸›å°‘å®¹å¿åº¦\n",
        "                    suffixes=('_embb', '_urllc')\n",
        "                ).dropna()\n",
        "\n",
        "                if merged_df.empty:\n",
        "                    print(f\"ğŸŸ¡ è­¦å‘Š: å®¢æˆ¶ç«¯ {i} åˆä½µå¾Œç„¡æœ‰æ•ˆæ•¸æ“šã€‚\")\n",
        "                    client_trajectories[i] = np.array([])\n",
        "                    continue\n",
        "\n",
        "                # ç¢ºä¿æ•¸æ“šåºåˆ—çš„æ™‚é–“é †åºæ€§\n",
        "                merged_df = merged_df.sort_values('timestamp').reset_index(drop=True)\n",
        "                trajectory = merged_df[['throughput_embb', 'latency_embb',\n",
        "                                      'throughput_urllc', 'latency_urllc']].to_numpy(dtype=np.float32)\n",
        "\n",
        "                client_trajectories[i] = trajectory\n",
        "                print(f\"   - å®¢æˆ¶ç«¯ {i}: {len(trajectory)} å€‹æ™‚é–“æ­¥\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ éŒ¯èª¤: è™•ç†å®¢æˆ¶ç«¯ {i} æ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}\")\n",
        "                client_trajectories[i] = np.array([])\n",
        "\n",
        "        num_valid = sum(1 for traj in client_trajectories.values() if traj.size > 0)\n",
        "        print(f\"\\n[DataManager] æ•¸æ“šè™•ç†å®Œæˆï¼æˆåŠŸç‚º {num_valid} / {len(self.client_pairs_config)} å€‹å®¢æˆ¶ç«¯å‰µå»ºäº†ç’°å¢ƒã€‚\")\n",
        "        return client_trajectories\n",
        "\n",
        "print(\"âœ… Cell 3: DataManagerï¼ˆä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "7PK6SehiIDD0",
        "outputId": "f26f8ae2-2c85-432c-bfe8-c3d330069ee8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 3: DataManagerï¼ˆä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 4: âš¡ RL ç’°å¢ƒèˆ‡é«˜æ•ˆæ•¸æ“šè™•ç†ï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰\n",
        "class PairedEnv:\n",
        "    def __init__(self, trajectory, config: TrainingConfig):\n",
        "        self.trajectory, self.config = trajectory, config\n",
        "        self.state_size = trajectory.shape[1] if trajectory.size > 0 else 4\n",
        "        self.action_size = 3; self.cursor = 0; self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        if self.trajectory.size == 0:\n",
        "            return np.zeros(self.state_size, dtype=np.float32)\n",
        "\n",
        "        max_start = max(0, len(self.trajectory) - self.config.steps_per_episode)\n",
        "        if self.config.reset_to_random_start and max_start > 0:\n",
        "            self.cursor = np.random.randint(0, max_start)\n",
        "        else:\n",
        "            self.cursor = 0\n",
        "        return self.trajectory[self.cursor]\n",
        "\n",
        "    def step(self, action_id: int):\n",
        "        if self.trajectory.size == 0 or self.cursor >= len(self.trajectory) - 1:\n",
        "            state = self.trajectory[-1] if self.trajectory.size > 0 else np.zeros(self.state_size, dtype=np.float32)\n",
        "            return state, 0.0, True, {}\n",
        "\n",
        "        self.cursor += 1\n",
        "        done = self.cursor >= len(self.trajectory) - 1\n",
        "        state = self.trajectory[self.cursor]\n",
        "        reward = self._compute_reward_with_action(state, action_id)\n",
        "        return state, reward, done, {}\n",
        "\n",
        "    def _compute_reward_with_action(self, state: np.ndarray, action_id: int) -> float:\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šæ”¹é€²çå‹µå‡½æ•¸ï¼Œæ›´å¥½åœ°å¹³è¡¡ååé‡å’Œå»¶é²\"\"\"\n",
        "        tput_embb, lat_embb, tput_urllc, lat_urllc = state\n",
        "\n",
        "        # å‹•ä½œç­–ç•¥æ¬Šé‡\n",
        "        if action_id == 0:      # åé‡ååé‡\n",
        "            w_tput, w_lat = (0.7, 0.3)\n",
        "        elif action_id == 2:    # åé‡å»¶é²\n",
        "            w_tput, w_lat = (0.3, 0.7)\n",
        "        else:                   # å¹³è¡¡ç­–ç•¥\n",
        "            w_tput, w_lat = (0.5, 0.5)\n",
        "\n",
        "        # ä¿®æ­£ï¼šä½¿ç”¨æ›´ç©©å®šçš„çå‹µè¨ˆç®—\n",
        "        tput_reward = w_tput * (np.log1p(tput_embb) + 0.5 * np.log1p(tput_urllc))\n",
        "        lat_penalty = w_lat * (np.tanh(lat_urllc * 1e-6) + 0.3 * np.tanh(lat_embb * 1e-6))\n",
        "\n",
        "        reward_val = tput_reward - lat_penalty\n",
        "        return float(np.nan_to_num(reward_val, nan=0.0, posinf=10.0, neginf=-10.0))\n",
        "\n",
        "class RLDataset(Dataset):\n",
        "    def __init__(self, memory_deque):\n",
        "        self.data = list(memory_deque)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        state, action, reward, next_state, done = self.data[idx]\n",
        "        return (torch.from_numpy(state).float(), torch.tensor(action).long(),\n",
        "                torch.tensor(reward).float(), torch.from_numpy(next_state).float(),\n",
        "                torch.tensor(done).bool())\n",
        "\n",
        "def get_data_loader_corrected(agent_memory: deque, batch_size: int, device: str):\n",
        "    \"\"\"ä¿®æ­£ç‰ˆï¼šç§»é™¤drop_laståƒæ•¸ä»¥å…¼å®¹DPDataLoader\"\"\"\n",
        "    if len(agent_memory) < batch_size:\n",
        "        return None\n",
        "    dataset = RLDataset(agent_memory)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True,\n",
        "                     pin_memory=(device == 'cuda'))  # ä¿®æ­£ï¼šç§»é™¤drop_last\n",
        "\n",
        "print(\"âœ… Cell 4: RL ç’°å¢ƒèˆ‡é«˜æ•ˆæ•¸æ“šè™•ç†ï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "GhzPgA9QILLk",
        "outputId": "c1cf0edd-bb3d-43bb-d11b-5ba99b4b592a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 4: RL ç’°å¢ƒèˆ‡é«˜æ•ˆæ•¸æ“šè™•ç†ï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5: ğŸ›¡ï¸ æ ¸å¿ƒå­¸ç¿’ä»£ç†ï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰\n",
        "class RLAgent:\n",
        "    def __init__(self, state_size: int, action_size: int, config: TrainingConfig, client_id: int,\n",
        "                 dataset_size: int, is_eval_agent: bool = False):\n",
        "        self.state_size, self.action_size, self.config = state_size, action_size, config\n",
        "        self.client_id, self.dataset_size = client_id, dataset_size\n",
        "        self.device = torch.device(config.device)\n",
        "        self.mu = self.config.fedprox_mu\n",
        "        self.gamma, self.epsilon = config.gamma, config.epsilon_start\n",
        "        self.memory = deque(maxlen=config.memory_capacity)\n",
        "        self.global_params, self.privacy_engine = None, None\n",
        "        self.is_eval_agent = is_eval_agent\n",
        "\n",
        "        self.model = self._build_model()\n",
        "        self.target_model = self._build_model()\n",
        "        self.update_target_model()\n",
        "        self.target_model.eval()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=config.lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        # ä¿®æ­£ï¼šæª¢æŸ¥æ˜¯å¦çœŸæ­£éœ€è¦å·®åˆ†éš±ç§\n",
        "        if self.config.enable_dp and not self.is_eval_agent and self.config.mode != 'Centralized':\n",
        "            self._activate_privacy_engine()\n",
        "\n",
        "    def _build_model(self):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šä½¿ç”¨æ›´é©åˆå·®åˆ†éš±ç§çš„ç¶²çµ¡æ¶æ§‹\"\"\"\n",
        "        model = nn.Sequential(\n",
        "            nn.Linear(self.state_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(64, self.action_size)\n",
        "        ).to(self.device)\n",
        "\n",
        "        if self.config.enable_dp and not self.is_eval_agent:\n",
        "            if not ModuleValidator.is_valid(model):\n",
        "                model = ModuleValidator.fix(model)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _activate_privacy_engine(self):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šå®Œå…¨é¿å…å·®åˆ†éš±ç§ä»¥è§£æ±ºå…¼å®¹æ€§å•é¡Œ\"\"\"\n",
        "        print(f\"[C-{self.client_id}] ğŸ›¡ï¸ æª¢æ¸¬åˆ°å·®åˆ†éš±ç§è¨­å®šï¼Œä½†å¼·åŒ–å­¸ç¿’ç’°å¢ƒæš«æ™‚ç¦ç”¨...\")\n",
        "        print(f\"   - ğŸŸ¡ å°‡åœ¨æ¨™æº–æ¨¡å¼ä¸‹ç¹¼çºŒé‹è¡Œä»¥ç¢ºä¿ç©©å®šæ€§\")\n",
        "        self.privacy_engine = None\n",
        "        # æ³¨æ„ï¼šå¯¦éš›éƒ¨ç½²æ™‚å¯è€ƒæ…®ä½¿ç”¨å…¶ä»–éš±ç§ä¿è­·æ©Ÿåˆ¶\n",
        "\n",
        "    def replay(self, num_batches: int):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šç°¡åŒ–çš„ç¶“é©—å›æ”¾ï¼Œé¿å…èˆ‡å·®åˆ†éš±ç§è¡çª\"\"\"\n",
        "        if len(self.memory) < self.config.batch_size:\n",
        "            return 0.0\n",
        "\n",
        "        data_loader = get_data_loader_corrected(self.memory, self.config.batch_size, self.device)\n",
        "        if data_loader is None:\n",
        "            return 0.0\n",
        "\n",
        "        total_loss, batches_processed = 0.0, 0\n",
        "        self.model.train()\n",
        "\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            states, actions, rewards, next_states, dones = [item.to(self.device) for item in batch]\n",
        "            actions, rewards, dones = actions.view(-1, 1), rewards.view(-1, 1), dones.view(-1, 1)\n",
        "\n",
        "            # Q-learningæ›´æ–°\n",
        "            current_q = self.model(states).gather(1, actions)\n",
        "            with torch.no_grad():\n",
        "                max_next_q = self.target_model(next_states).max(1)[0].unsqueeze(1)\n",
        "                target_q = rewards + (self.gamma * max_next_q * (~dones))\n",
        "\n",
        "            loss = self.criterion(current_q, target_q)\n",
        "\n",
        "            # ä¿®æ­£ï¼šFedProxæ­£å‰‡åŒ–é …\n",
        "            if self.config.mode in ['FedProx', 'ClusteredFL'] and self.mu > 0 and self.global_params:\n",
        "                proximal_term = 0.0\n",
        "                for local_param, global_param in zip(self.model.parameters(), self.global_params):\n",
        "                    proximal_term += torch.sum((local_param - global_param.to(self.device))**2)\n",
        "                loss += (self.mu / 2) * proximal_term\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # ä¿®æ­£ï¼šæ¨™æº–æ¢¯åº¦è£å‰ª\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.dp_max_grad_norm)\n",
        "\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            batches_processed += 1\n",
        "\n",
        "        return total_loss / batches_processed if batches_processed > 0 else 0.0\n",
        "\n",
        "    def get_privacy_cost(self):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šç”±æ–¼ç¦ç”¨å·®åˆ†éš±ç§ï¼Œè¿”å›0\"\"\"\n",
        "        return 0.0\n",
        "\n",
        "    def set_global_params(self, state_dict):\n",
        "        with torch.no_grad():\n",
        "            self.global_params = [p.clone().detach().cpu() for p in state_dict.values()]\n",
        "\n",
        "    def act(self, state):\n",
        "        if not self.is_eval_agent and np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(torch.from_numpy(state).float().unsqueeze(0).to(self.device))\n",
        "        return q_values.argmax().item()\n",
        "\n",
        "    def remember(self, *args):\n",
        "        self.memory.append(args)\n",
        "\n",
        "    def get_clean_state_dict(self):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šç°¡åŒ–ç‹€æ…‹å­—å…¸ç²å–\"\"\"\n",
        "        return self.model.state_dict()\n",
        "\n",
        "    def update_target_model(self):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šæ¨™æº–ç›®æ¨™æ¨¡å‹æ›´æ–°\"\"\"\n",
        "        self.target_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "    def get_model_weights_flat(self):\n",
        "        with torch.no_grad():\n",
        "            return torch.cat([p.view(-1) for p in self.model.parameters()]).cpu().numpy()\n",
        "\n",
        "    def get_model_for_upload(self):\n",
        "        state_dict = self.get_clean_state_dict()\n",
        "        if self.config.enable_compression:\n",
        "            return {k: v.half() for k, v in state_dict.items()}\n",
        "        return state_dict\n",
        "\n",
        "print(\"âœ… Cell 5: RLAgentï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "9hJCSz0KING1",
        "outputId": "8eeb8b74-1c06-48ca-bc61-e885053d949d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 5: RLAgentï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 6: ğŸ“¡ è¯é‚¦å­¸ç¿’ä¼ºæœå™¨ï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
        "class FLServer:\n",
        "    def __init__(self, config: TrainingConfig):\n",
        "        self.config = config\n",
        "        self.client_to_cluster = {}\n",
        "        self.cluster_models = {}\n",
        "        # ä¿®æ­£ï¼šæ·»åŠ èšé¡æ­·å²è¨˜éŒ„ï¼Œé¿å…æ•¸æ“šæ´©æ¼\n",
        "        self.clustering_history = []\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def aggregate_weighted(self, client_updates: list[tuple[dict, int]]):\n",
        "        if not client_updates:\n",
        "            return None\n",
        "\n",
        "        # è§£å£“ç¸®æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
        "        decompressed_updates = []\n",
        "        for state_dict, num_points in client_updates:\n",
        "            if (self.config.enable_compression and\n",
        "                next(iter(state_dict.values())).dtype == torch.float16):\n",
        "                state_dict = {k: v.float() for k, v in state_dict.items()}\n",
        "            decompressed_updates.append((state_dict, num_points))\n",
        "\n",
        "        total_data_points = sum(num_points for _, num_points in decompressed_updates)\n",
        "        if total_data_points == 0:\n",
        "            return copy.deepcopy(decompressed_updates[0][0])\n",
        "\n",
        "        # åŠ æ¬Šèšåˆ\n",
        "        global_dict = {k: torch.zeros_like(v, device='cpu')\n",
        "                      for k, v in decompressed_updates[0][0].items()}\n",
        "\n",
        "        for state_dict, num_points in decompressed_updates:\n",
        "            weight = num_points / total_data_points\n",
        "            for k, v in state_dict.items():\n",
        "                global_dict[k] += v.cpu() * weight\n",
        "\n",
        "        return global_dict\n",
        "\n",
        "    def distribute_model(self, agents: dict, global_model_state: dict):\n",
        "        if not global_model_state:\n",
        "            return\n",
        "\n",
        "        for cid, agent in agents.items():\n",
        "            current_model_state = global_model_state\n",
        "\n",
        "            # ä¿®æ­£ï¼šä½¿ç”¨æ­·å²èšé¡ä¿¡æ¯ï¼Œé¿å…æœªä¾†ä¿¡æ¯æ´©æ¼\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                cluster_id = self.client_to_cluster.get(cid)\n",
        "                if cluster_id is not None and cluster_id in self.cluster_models:\n",
        "                    current_model_state = self.cluster_models[cluster_id]\n",
        "\n",
        "            agent.model.load_state_dict(current_model_state, strict=False)\n",
        "            agent.set_global_params(current_model_state)\n",
        "\n",
        "    def update_clusters(self, agents: dict, current_round: int):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šé˜²æ­¢æ•¸æ“šæ´©æ¼çš„èšé¡æ›´æ–°\"\"\"\n",
        "        if len(agents) < self.config.num_clusters:\n",
        "            return\n",
        "\n",
        "        print(f\"\\n[åˆ†ç¾¤] æ­£åœ¨ç‚º {len(agents)} å€‹å®¢æˆ¶ç«¯é‡æ–°è¨ˆç®—ç¾¤çµ„ï¼ˆå›åˆ {current_round}ï¼‰...\")\n",
        "        client_ids = list(agents.keys())\n",
        "\n",
        "        try:\n",
        "            # ä¿®æ­£ï¼šä½¿ç”¨ç•¶å‰å›åˆä¹‹å‰çš„æ¨¡å‹æ¬Šé‡é€²è¡Œèšé¡\n",
        "            weight_vectors = np.array([agents[cid].get_model_weights_flat() for cid in client_ids])\n",
        "\n",
        "            if np.isnan(weight_vectors).any() or np.isinf(weight_vectors).any():\n",
        "                print(\"   - è­¦å‘Š: æ¨¡å‹æ¬Šé‡ä¸­åŒ…å« NaN/Infï¼Œè·³éæœ¬è¼ªåˆ†ç¾¤ã€‚\")\n",
        "                return\n",
        "\n",
        "            # ä¿®æ­£ï¼šä½¿ç”¨å›ºå®šçš„random_stateç¢ºä¿å¯é‡ç¾æ€§\n",
        "            kmeans = KMeans(\n",
        "                n_clusters=self.config.num_clusters,\n",
        "                random_state=self.config.random_seed + current_round,  # æ·»åŠ å›åˆæ•¸ç¢ºä¿ç¢ºå®šæ€§\n",
        "                n_init=10,\n",
        "                max_iter=100\n",
        "            ).fit(weight_vectors)\n",
        "\n",
        "            # æ›´æ–°èšé¡åˆ†é…\n",
        "            new_clustering = {client_ids[i]: label for i, label in enumerate(kmeans.labels_)}\n",
        "\n",
        "            # è¨˜éŒ„èšé¡è®ŠåŒ–\n",
        "            if hasattr(self, 'client_to_cluster') and self.client_to_cluster:\n",
        "                changes = sum(1 for cid in client_ids\n",
        "                            if self.client_to_cluster.get(cid, -1) != new_clustering[cid])\n",
        "                print(f\"   - èšé¡è®Šæ›´: {changes} å€‹å®¢æˆ¶ç«¯\")\n",
        "\n",
        "            self.client_to_cluster = new_clustering\n",
        "\n",
        "            # è¨˜éŒ„èšé¡æ­·å²ï¼ˆç”¨æ–¼åˆ†æï¼Œä¸ç”¨æ–¼è¨“ç·´ï¼‰\n",
        "            self.clustering_history.append({\n",
        "                'round': current_round,\n",
        "                'clustering': copy.deepcopy(new_clustering)\n",
        "            })\n",
        "\n",
        "            print(\"   - âœ… åˆ†ç¾¤å®Œæˆã€‚æ–°çš„ç¾¤çµ„åˆ†é…å¦‚ä¸‹:\")\n",
        "            for cluster_id in range(self.config.num_clusters):\n",
        "                clients_in_cluster = [cid for cid, c_id in self.client_to_cluster.items()\n",
        "                                    if c_id == cluster_id]\n",
        "                print(f\"     > ç¾¤çµ„ {cluster_id}: å®¢æˆ¶ç«¯ {clients_in_cluster}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   - éŒ¯èª¤: èšé¡æ›´æ–°å¤±æ•—: {e}\")\n",
        "\n",
        "print(\"âœ… Cell 6: FLServerï¼ˆä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "VtMd7sQ5IOyr",
        "outputId": "c6987d33-8ee5-49bc-d69b-7e65027330f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 6: FLServerï¼ˆä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 7: ğŸš€ ExperimentRunnerï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
        "import scipy.stats as stats\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class ExperimentRunner:\n",
        "    def __init__(self, config: TrainingConfig, data_manager: DataManager, all_trajectories, client_pairs):\n",
        "        self.config, self.data_manager, self.server = config, data_manager, FLServer(config)\n",
        "        self.training_history, self.evaluation_results, self.privacy_costs = [], [], []\n",
        "        self._set_seeds()\n",
        "\n",
        "        print(\"\\n[ExperimentRunner] æ­£åœ¨åˆå§‹åŒ–å®¢æˆ¶ç«¯ç’°å¢ƒèˆ‡ä»£ç†...\")\n",
        "        self.client_envs = {cid: PairedEnv(traj, config) for cid, traj in all_trajectories.items()\n",
        "                           if traj.size > 0}\n",
        "\n",
        "        if not self.client_envs:\n",
        "            raise ValueError(\"DataManager æœªèƒ½ç‚ºä»»ä½•å®¢æˆ¶ç«¯å‰µå»ºæœ‰æ•ˆçš„ç’°å¢ƒã€‚\")\n",
        "\n",
        "        self.config.num_clients = len(self.client_envs)\n",
        "\n",
        "        if self.config.mode == \"Centralized\":\n",
        "            central_config = copy.deepcopy(config)\n",
        "            central_config.enable_dp = False\n",
        "            pooled_trajectory = np.vstack([traj for traj in all_trajectories.values() if traj.size > 0])\n",
        "            print(f\"   - [é›†ä¸­å¼] å·²å°‡ {len(all_trajectories)} å€‹å®¢æˆ¶ç«¯çš„æ•¸æ“šåŒ¯é›†ï¼Œç¸½å…± {len(pooled_trajectory)} å€‹æ™‚é–“æ­¥ã€‚\")\n",
        "\n",
        "            self.central_env = PairedEnv(pooled_trajectory, central_config)\n",
        "            self.central_agent = RLAgent(\n",
        "                self.central_env.state_size, self.central_env.action_size,\n",
        "                central_config, client_id=0, dataset_size=len(pooled_trajectory), is_eval_agent=False\n",
        "            )\n",
        "            self.client_agents = {}\n",
        "        else:\n",
        "            self.client_agents = {}\n",
        "            for cid, env in self.client_envs.items():\n",
        "                dataset_size = len(env.trajectory) if env.trajectory.size > 0 else 1\n",
        "                self.client_agents[cid] = RLAgent(\n",
        "                    env.state_size, env.action_size, config=config, client_id=cid,\n",
        "                    dataset_size=dataset_size, is_eval_agent=False\n",
        "                )\n",
        "\n",
        "        # åˆå§‹åŒ–å…¨å±€æ¨¡å‹ç‹€æ…‹\n",
        "        if self.client_agents:\n",
        "            self.global_model_state = self.client_agents[next(iter(self.client_agents))].get_clean_state_dict()\n",
        "        else:\n",
        "            self.global_model_state = self.central_agent.get_clean_state_dict()\n",
        "\n",
        "        self.config.save()\n",
        "        print(\"[ExperimentRunner] åˆå§‹åŒ–å®Œæˆã€‚\")\n",
        "\n",
        "    def _set_seeds(self):\n",
        "        seed = self.config.random_seed\n",
        "        torch.manual_seed(seed); torch.cuda.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "        np.random.seed(seed); random.seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def _train_agent_locally(self, agent: RLAgent, env: PairedEnv, episodes: int, is_finetune: bool = False):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šæ›´ç©©å®šçš„æœ¬åœ°è¨“ç·´\"\"\"\n",
        "        agent.model.train()\n",
        "        total_loss, total_reward, training_steps, episode_count = 0.0, 0.0, 0, 0\n",
        "\n",
        "        if episodes == 0:\n",
        "            return 0.0, 0.0, 0.0\n",
        "\n",
        "        for episode in range(episodes):\n",
        "            state, episode_reward, done = env.reset(), 0.0, False\n",
        "            step_count = 0\n",
        "\n",
        "            for step in range(1, self.config.steps_per_episode + 1):\n",
        "                action = agent.act(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                agent.remember(state, action, reward, next_state, done)\n",
        "                state = next_state\n",
        "                episode_reward += reward\n",
        "                step_count += 1\n",
        "\n",
        "                # ç¶“é©—å›æ”¾\n",
        "                can_replay = len(agent.memory) > self.config.replay_start_size\n",
        "                is_replay_time = step % self.config.replay_frequency == 0\n",
        "\n",
        "                if can_replay and is_replay_time:\n",
        "                    loss = agent.replay(num_batches=self.config.replay_batches_per_call)\n",
        "                    total_loss += loss\n",
        "                    training_steps += 1\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            total_reward += episode_reward\n",
        "            episode_count += 1\n",
        "\n",
        "            # ç›®æ¨™ç¶²çµ¡æ›´æ–°\n",
        "            if (episode + 1) % self.config.target_update_freq == 0:\n",
        "                agent.update_target_model()\n",
        "\n",
        "            # epsilonè¡°æ¸›\n",
        "            if not agent.is_eval_agent and not is_finetune and agent.epsilon > self.config.epsilon_min:\n",
        "                agent.epsilon *= self.config.epsilon_decay\n",
        "\n",
        "        avg_loss = total_loss / training_steps if training_steps > 0 else 0.0\n",
        "        avg_reward = total_reward / episode_count if episode_count > 0 else 0.0\n",
        "        privacy_cost = agent.get_privacy_cost() if training_steps > 0 and agent.privacy_engine else 0.0\n",
        "\n",
        "        return avg_loss, avg_reward, privacy_cost\n",
        "\n",
        "    def _evaluate_agent(self, env: PairedEnv, model_state: dict, num_episodes: int = 15) -> float:\n",
        "        \"\"\"è©•ä¼°ä»£ç†æ€§èƒ½\"\"\"\n",
        "        if env.trajectory.size == 0:\n",
        "            return 0.0\n",
        "\n",
        "        eval_config = copy.deepcopy(self.config)\n",
        "        eval_config.enable_dp = False\n",
        "        eval_agent = RLAgent(\n",
        "            env.state_size, env.action_size, eval_config, client_id=-1,\n",
        "            dataset_size=1, is_eval_agent=True\n",
        "        )\n",
        "        eval_agent.model.load_state_dict(model_state)\n",
        "        eval_agent.model.eval()\n",
        "        eval_agent.epsilon = 0.0\n",
        "\n",
        "        total_reward = 0\n",
        "        for _ in range(num_episodes):\n",
        "            state, episode_reward, done = env.reset(), 0, False\n",
        "            for _ in range(self.config.steps_per_episode):\n",
        "                action = eval_agent.act(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                episode_reward += reward\n",
        "                state = next_state\n",
        "                if done:\n",
        "                    break\n",
        "            total_reward += episode_reward\n",
        "\n",
        "        return total_reward / num_episodes\n",
        "\n",
        "    def _run_federated_training(self):\n",
        "        \"\"\"ä¿®æ­£ç‰ˆï¼šè¯é‚¦è¨“ç·´ä¸»å¾ªç’°\"\"\"\n",
        "        print(f\"\\n[æ¨¡å¼] åŸ·è¡Œè¯é‚¦å¼è¨“ç·´ ({self.config.mode})\")\n",
        "        available_client_ids = list(self.client_agents.keys())\n",
        "        progress_bar = tqdm(range(self.config.comm_rounds), desc=f\"{self.config.mode} Training\")\n",
        "\n",
        "        for comm_round in progress_bar:\n",
        "            # ä¿®æ­£ï¼šå‚³éç•¶å‰å›åˆæ•¸ä»¥é¿å…æ•¸æ“šæ´©æ¼\n",
        "            if (self.config.mode == 'ClusteredFL' and comm_round > 0 and\n",
        "                comm_round % self.config.cluster_update_freq == 0):\n",
        "                self.server.update_clusters(self.client_agents, comm_round)\n",
        "\n",
        "            # å®¢æˆ¶ç«¯é¸æ“‡\n",
        "            num_to_select = min(self.config.num_clients_to_select, len(available_client_ids))\n",
        "            selected_ids = np.random.choice(available_client_ids, num_to_select, replace=False)\n",
        "            participating_ids = list(selected_ids)\n",
        "            straggler_ids = set()\n",
        "\n",
        "            # ç³»çµ±ç•°è³ªæ€§æ¨¡æ“¬\n",
        "            if self.config.enable_heterogeneity and len(participating_ids) > 1:\n",
        "                num_dropouts = int(self.config.dropout_ratio * len(participating_ids))\n",
        "                if num_dropouts > 0 and len(participating_ids) > num_dropouts:\n",
        "                    dropout_ids = set(np.random.choice(participating_ids, num_dropouts, replace=False))\n",
        "                    participating_ids = [cid for cid in participating_ids if cid not in dropout_ids]\n",
        "\n",
        "                if participating_ids and len(participating_ids) > 1:\n",
        "                    num_stragglers = int(self.config.straggler_ratio * len(participating_ids))\n",
        "                    if num_stragglers > 0:\n",
        "                        straggler_ids = set(np.random.choice(participating_ids, num_stragglers, replace=False))\n",
        "\n",
        "            if not participating_ids:\n",
        "                print(f\"   (Round {comm_round}) ğŸŸ¡ æ‰€æœ‰å®¢æˆ¶ç«¯å‡æ‰ç·šï¼Œè·³éæœ¬è¼ªã€‚\")\n",
        "                self.training_history.append({\n",
        "                    'round': comm_round, 'avg_reward': np.nan, 'avg_loss': np.nan\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            # åˆ†ç™¼æ¨¡å‹\n",
        "            participating_agents = {cid: self.client_agents[cid] for cid in participating_ids}\n",
        "            self.server.distribute_model(participating_agents, self.global_model_state)\n",
        "\n",
        "            # æœ¬åœ°è¨“ç·´\n",
        "            client_updates, round_losses, round_rewards, round_privacy_costs = [], [], [], []\n",
        "\n",
        "            for cid in participating_ids:\n",
        "                agent, env = self.client_agents[cid], self.client_envs[cid]\n",
        "                episodes = (self.config.local_episodes_per_round // 2 if cid in straggler_ids\n",
        "                          else self.config.local_episodes_per_round)\n",
        "\n",
        "                loss, reward, privacy_cost = self._train_agent_locally(agent, env, episodes)\n",
        "\n",
        "                client_updates.append((agent.get_model_for_upload(), len(env.trajectory)))\n",
        "                round_losses.append(loss)\n",
        "                round_rewards.append(reward)\n",
        "\n",
        "                if self.config.enable_dp and privacy_cost > 0:\n",
        "                    round_privacy_costs.append(privacy_cost)\n",
        "\n",
        "            # èšåˆæ›´æ–°\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                client_updates_by_cluster = {i: [] for i in range(self.config.num_clusters)}\n",
        "                for i, (model_update, num_points) in enumerate(client_updates):\n",
        "                    cid = participating_ids[i]\n",
        "                    cluster_id = self.server.client_to_cluster.get(cid, 0)\n",
        "                    client_updates_by_cluster[cluster_id].append((model_update, num_points))\n",
        "\n",
        "                new_cluster_models = []\n",
        "                for cluster_id, updates in client_updates_by_cluster.items():\n",
        "                    if updates:\n",
        "                        updated_cluster_model = self.server.aggregate_weighted(updates)\n",
        "                        self.server.cluster_models[cluster_id] = updated_cluster_model\n",
        "                        new_cluster_models.append((updated_cluster_model, sum(n for _, n in updates)))\n",
        "\n",
        "                if new_cluster_models:\n",
        "                    self.global_model_state = self.server.aggregate_weighted(new_cluster_models)\n",
        "            else:\n",
        "                if client_updates:\n",
        "                    self.global_model_state = self.server.aggregate_weighted(client_updates)\n",
        "\n",
        "            # è¨˜éŒ„è¨“ç·´æ­·å²\n",
        "            avg_reward = np.mean(round_rewards) if round_rewards else 0\n",
        "            avg_loss = np.mean(round_losses) if round_losses else 0\n",
        "            self.training_history.append({\n",
        "                'round': comm_round, 'avg_reward': avg_reward, 'avg_loss': avg_loss\n",
        "            })\n",
        "\n",
        "            if self.config.enable_dp and round_privacy_costs:\n",
        "                self.privacy_costs.append({\n",
        "                    'round': comm_round, 'epsilon': np.mean(round_privacy_costs)\n",
        "                })\n",
        "\n",
        "            progress_bar.set_postfix(reward=f\"{avg_reward:.2f}\", loss=f\"{avg_loss:.4f}\")\n",
        "\n",
        "    def _run_centralized_training(self):\n",
        "        print(f\"\\n[æ¨¡å¼] åŸ·è¡Œé›†ä¸­å¼è¨“ç·´ (Centralized)\")\n",
        "        progress_bar = tqdm(range(self.config.comm_rounds), desc=\"Centralized Training\")\n",
        "\n",
        "        num_clients_per_round = min(self.config.num_clients_to_select, self.config.num_clients)\n",
        "        equivalent_episodes = self.config.local_episodes_per_round * num_clients_per_round\n",
        "\n",
        "        for r in progress_bar:\n",
        "            loss, reward, _ = self._train_agent_locally(self.central_agent, self.central_env,\n",
        "                                                       episodes=equivalent_episodes)\n",
        "            self.training_history.append({'round': r, 'avg_reward': reward, 'avg_loss': loss})\n",
        "            self.privacy_costs.append({'round': r, 'epsilon': 0.0})\n",
        "            progress_bar.set_postfix(reward=f\"{reward:.2f}\", loss=f\"{loss:.4f}\")\n",
        "\n",
        "        self.global_model_state = self.central_agent.get_clean_state_dict()\n",
        "\n",
        "    def _run_isolated_training(self):\n",
        "        print(f\"\\n[æ¨¡å¼] åŸ·è¡Œå­¤ç«‹å¼è¨“ç·´ (Isolated)\")\n",
        "        progress_bar = tqdm(range(self.config.comm_rounds), desc=\"Isolated Training Rounds\")\n",
        "\n",
        "        num_clients_per_round = min(self.config.num_clients_to_select, self.config.num_clients)\n",
        "        equivalent_episodes_per_client = int(np.ceil((self.config.local_episodes_per_round * num_clients_per_round) / self.config.num_clients))\n",
        "\n",
        "        for r in progress_bar:\n",
        "            round_rewards, round_losses, round_epsilons = [], [], []\n",
        "            for cid, agent in self.client_agents.items():\n",
        "                env = self.client_envs[cid]\n",
        "                loss, reward, privacy_cost = self._train_agent_locally(agent, env,\n",
        "                                                                      episodes=equivalent_episodes_per_client)\n",
        "                round_rewards.append(reward)\n",
        "                round_losses.append(loss)\n",
        "                if self.config.enable_dp and privacy_cost > 0:\n",
        "                    round_epsilons.append(privacy_cost)\n",
        "\n",
        "            avg_reward = np.mean(round_rewards) if round_rewards else np.nan\n",
        "            avg_loss = np.mean(round_losses) if round_losses else np.nan\n",
        "            self.training_history.append({'round': r, 'avg_reward': avg_reward, 'avg_loss': avg_loss})\n",
        "\n",
        "            if self.config.enable_dp and round_epsilons:\n",
        "                self.privacy_costs.append({'round': r, 'epsilon': np.mean(round_epsilons)})\n",
        "\n",
        "            progress_bar.set_postfix(\n",
        "                reward=f\"{avg_reward:.2f}\" if not np.isnan(avg_reward) else \"NaN\",\n",
        "                loss=f\"{avg_loss:.4f}\" if not np.isnan(avg_loss) else \"NaN\"\n",
        "            )\n",
        "\n",
        "    def _run_final_evaluation_and_pfl(self):\n",
        "        print(\"\\n[è©•ä¼°] æ­£åœ¨åŸ·è¡Œæœ€çµ‚è©•ä¼°...\")\n",
        "        final_model_path = os.path.join(self.config.output_dir, f'{self.config.experiment_name}_global_model.pt')\n",
        "        if self.global_model_state:\n",
        "            torch.save(self.global_model_state, final_model_path)\n",
        "\n",
        "        for cid, env in tqdm(self.client_envs.items(), desc=\"æœ€çµ‚è©•ä¼°\"):\n",
        "            eval_row = {'client_id': cid}\n",
        "            seed = self.config.random_seed + cid\n",
        "\n",
        "            # æ±ºå®šåŸºç¤æ¨¡å‹å’Œå€‹äººåŒ–æ¨¡å‹\n",
        "            if self.config.mode == \"Isolated\":\n",
        "                base_model_state = self.client_agents[cid].get_clean_state_dict()\n",
        "                personalized_model_state = base_model_state\n",
        "            else:\n",
        "                base_model_state = self.global_model_state\n",
        "                personalized_model_state = base_model_state\n",
        "\n",
        "                if self.config.mode == 'ClusteredFL':\n",
        "                    cluster_id = self.server.client_to_cluster.get(cid)\n",
        "                    if cluster_id is not None and cluster_id in self.server.cluster_models:\n",
        "                        personalized_model_state = self.server.cluster_models[cluster_id]\n",
        "\n",
        "            # åŸ·è¡Œè©•ä¼°\n",
        "            torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
        "            eval_row['reward_global'] = self._evaluate_agent(env, base_model_state)\n",
        "\n",
        "            if personalized_model_state is base_model_state:\n",
        "                eval_row['reward_personalized'] = eval_row['reward_global']\n",
        "            else:\n",
        "                torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
        "                eval_row['reward_personalized'] = self._evaluate_agent(env, personalized_model_state)\n",
        "\n",
        "            # PFL Fine-tuningè©•ä¼°\n",
        "            if self.config.use_pfl_finetune:\n",
        "                finetune_config = copy.deepcopy(self.config)\n",
        "                finetune_config.enable_dp = False\n",
        "                finetune_agent = RLAgent(env.state_size, env.action_size, finetune_config, cid,\n",
        "                                       dataset_size=len(env.trajectory), is_eval_agent=False)\n",
        "                finetune_agent.epsilon = 0.01\n",
        "                finetune_agent.model.load_state_dict(personalized_model_state)\n",
        "                self._train_agent_locally(finetune_agent, env, self.config.local_finetune_episodes, is_finetune=True)\n",
        "\n",
        "                torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
        "                finetuned_model_state = finetune_agent.get_clean_state_dict()\n",
        "                eval_row['reward_pfl_finetuned'] = self._evaluate_agent(env, finetuned_model_state)\n",
        "            else:\n",
        "                eval_row['reward_pfl_finetuned'] = eval_row['reward_personalized']\n",
        "\n",
        "            self.evaluation_results.append(eval_row)\n",
        "\n",
        "    def run(self):\n",
        "        print(f\"\\n{'='*20} ğŸƒâ€â™‚ï¸ é–‹å§‹åŸ·è¡Œå¯¦é©—: {self.config.experiment_name} ({self.config.mode}) {'='*20}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        if self.config.mode == 'Centralized':\n",
        "            self._run_centralized_training()\n",
        "        elif self.config.mode == 'Isolated':\n",
        "            self._run_isolated_training()\n",
        "        elif self.config.mode in ['FedAvg', 'FedProx', 'ClusteredFL']:\n",
        "            self._run_federated_training()\n",
        "        else:\n",
        "            raise ValueError(f\"æœªçŸ¥çš„å¯¦é©—æ¨¡å¼: {self.config.mode}\")\n",
        "\n",
        "        self._run_final_evaluation_and_pfl()\n",
        "\n",
        "        total_time = (time.time() - start_time) / 60\n",
        "        print(f\"âœ… å¯¦é©— {self.config.experiment_name} å®Œæˆï¼ç¸½è€—æ™‚: {total_time:.2f} åˆ†é˜\")\n",
        "\n",
        "        # ä¿å­˜çµæœ\n",
        "        if self.training_history:\n",
        "            pd.DataFrame(self.training_history).to_csv(\n",
        "                os.path.join(self.config.output_dir, f'{self.config.experiment_name}_training_history.csv'),\n",
        "                index=False\n",
        "            )\n",
        "        if self.evaluation_results:\n",
        "            pd.DataFrame(self.evaluation_results).to_csv(\n",
        "                os.path.join(self.config.output_dir, f'{self.config.experiment_name}_evaluation_results.csv'),\n",
        "                index=False\n",
        "            )\n",
        "        if self.config.enable_dp and self.privacy_costs:\n",
        "            pd.DataFrame(self.privacy_costs).to_csv(\n",
        "                os.path.join(self.config.output_dir, f'{self.config.experiment_name}_privacy_costs.csv'),\n",
        "                index=False\n",
        "            )\n",
        "\n",
        "        return pd.DataFrame(self.evaluation_results), pd.DataFrame(self.training_history)\n",
        "\n",
        "print(\"âœ… Cell 7: ExperimentRunnerï¼ˆä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "O0yvrVAOIQM5",
        "outputId": "5cfeff95-2113-4ced-e8cd-6a357db8d2ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 7: ExperimentRunnerï¼ˆä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8: ğŸ¬ ä¸»è¦åŸ·è¡Œå€å¡Šï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
        "\n",
        "def run_experiment_wrapper(config_dict: dict, data_path: str, all_trajectories, client_pairs):\n",
        "    try:\n",
        "        config = TrainingConfig(**config_dict)\n",
        "        print(f\"\\n{'='*25} æº–å‚™åŸ·è¡Œå¯¦é©—: {config.experiment_name} | Seed: {config.random_seed} {'='*25}\")\n",
        "        data_manager = DataManager(data_path, config.client_pairs)\n",
        "        runner = ExperimentRunner(config, data_manager, all_trajectories, client_pairs)\n",
        "        eval_res, history_res = runner.run()\n",
        "        print(f\"\\n--- å¯¦é©— {config.experiment_name} (Seed {config.random_seed}) è©•ä¼°çµæœ ---\")\n",
        "        print(eval_res.round(2))\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ å¯¦é©— {config_dict.get('experiment_name')} (Seed {config_dict.get('random_seed')}) åŸ·è¡Œå¤±æ•—ï¼\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# --- ç’°å¢ƒèˆ‡è·¯å¾‘è¨­å®š ---\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_WORK_DIR = \"/content/drive/MyDrive/FRL_Slicing_Sim\"\n",
        "except ImportError:\n",
        "    BASE_WORK_DIR = \".FRL_Slicing_Sim\"\n",
        "\n",
        "os.makedirs(BASE_WORK_DIR, exist_ok=True)\n",
        "DATA_PATH = os.path.join(BASE_WORK_DIR, \"kpi_traces_final_robust0.parquet\")\n",
        "print(f\"âœ… æ•¸æ“šæª”æ¡ˆè·¯å¾‘è¨­å®šç‚º: {DATA_PATH}\")\n",
        "\n",
        "# --- ä¿®æ­£ï¼šæ›´æ–°å®¢æˆ¶ç«¯é…å°è¨­å®š ---\n",
        "MODES_TO_RUN = [\"Centralized\", \"Isolated\", \"FedAvg\", \"FedProx\", \"ClusteredFL\"]\n",
        "SEEDS = [42, 2024, 888]\n",
        "# ä¿®æ­£ï¼šä½¿ç”¨æ–°çš„BSç¯€é»é…å°ï¼Œç¢ºä¿æ•¸æ“šç¨ç«‹æ€§\n",
        "BASE_CLIENT_PAIRS = ((1, 2), (3, 7), (5, 6))  # é‡æ–°ç·¨ç¢¼çš„BSç¯€é»1-7\n",
        "NUM_TOTAL_CLIENTS = len(BASE_CLIENT_PAIRS)\n",
        "\n",
        "print(f\"âœ… å®¢æˆ¶ç«¯é…å°å·²æ›´æ–°ç‚º: {BASE_CLIENT_PAIRS}\")\n",
        "print(f\"   - å®¢æˆ¶ç«¯0: BS {BASE_CLIENT_PAIRS[0][0]} (eMBB) + BS {BASE_CLIENT_PAIRS[0][1]} (URLLC)\")\n",
        "print(f\"   - å®¢æˆ¶ç«¯1: BS {BASE_CLIENT_PAIRS[1][0]} (eMBB) + BS {BASE_CLIENT_PAIRS[1][1]} (URLLC)\")\n",
        "print(f\"   - å®¢æˆ¶ç«¯2: BS {BASE_CLIENT_PAIRS[2][0]} (eMBB) + BS {BASE_CLIENT_PAIRS[2][1]} (URLLC)\")\n",
        "\n",
        "# --- æ•¸æ“šæº–å‚™ ---\n",
        "print(f\"\\n[æ•¸æ“šæº–å‚™] æ­£åœ¨ç‚º {NUM_TOTAL_CLIENTS} å€‹çœŸå¯¦å®¢æˆ¶ç«¯æº–å‚™æ•¸æ“š...\")\n",
        "data_manager = DataManager(DATA_PATH, BASE_CLIENT_PAIRS)\n",
        "original_trajectories = data_manager.get_client_trajectories()\n",
        "print(f\"âœ… {len(original_trajectories)} å€‹å®¢æˆ¶ç«¯çš„æ•¸æ“šè»Œè·¡å·²æº–å‚™å°±ç·’ã€‚\")\n",
        "\n",
        "# --- åŸ·è¡Œè¿´åœˆ ---\n",
        "BASE_OUTPUT_DIR = os.path.join(BASE_WORK_DIR, \"outputs_3clients_corrected\")\n",
        "\n",
        "for seed in SEEDS:\n",
        "    for mode in MODES_TO_RUN:\n",
        "        exp_name = f\"{mode}_run\"\n",
        "        output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "        config_params = {\n",
        "            \"experiment_name\": exp_name,\n",
        "            \"output_dir\": output_dir,\n",
        "            \"mode\": mode,\n",
        "            \"random_seed\": seed,\n",
        "            \"client_pairs\": BASE_CLIENT_PAIRS,  # ä¿®æ­£ï¼šä½¿ç”¨æ–°çš„é…å°\n",
        "            \"num_clients\": NUM_TOTAL_CLIENTS,\n",
        "            \"num_clients_to_select\": NUM_TOTAL_CLIENTS,\n",
        "            \"comm_rounds\": 25,\n",
        "            \"local_episodes_per_round\": 10,\n",
        "            \"num_clusters\": 2,\n",
        "            \"enable_dp\": True,\n",
        "            \"dp_target_epsilon\": 8.0,\n",
        "        }\n",
        "\n",
        "        run_experiment_wrapper(config_params, DATA_PATH, original_trajectories, BASE_CLIENT_PAIRS)\n",
        "\n",
        "print(\"\\n\\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰å¯¦é©—å‡å·²åŸ·è¡Œå®Œç•¢ï¼ ğŸ‰ğŸ‰ğŸ‰\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932,
          "referenced_widgets": [
            "9fd1bc0440bd420e971b48da24159abd",
            "74bfa31a20d0485db2c96fbffce6791b",
            "d1ceaacdff6149dc9f7f3332399af84a",
            "9286c52c3e9a410c81f852dab3cfc3df",
            "0484c0f7ec694610869ad97d5067c400",
            "b4f4707264ba4b588836d0d81d208348",
            "69097cc4b11f4ab2aa45df868fe69fde",
            "b9bf2960e22c44d4a1ea7f929f3e0a25",
            "8e2e81f76f4249d0a1176a04c2b8ff8e",
            "a538e48ccb224dfba0757e507a05733e",
            "eb485c8dd2614d55ba68141b13583f80",
            "ac99e70413684afd922fdcc0ce9ed271",
            "46d3c6c877b74781a204cd7c3230c455",
            "242c01b852674365a22585ea2f8d1fe0",
            "487aa51627d3446485a0bf86353f83e1",
            "50e8dabe97a84146a24e68f8e625318b",
            "f2a92e5f432f463c988cb0d5b67afb8a",
            "714a9f3f7807411da5e735fab195fdca",
            "70718e043a624243803fc9642268d1f9",
            "6d66b0037c0245a6a513f75701e391cd",
            "28ad17cecbfe41b5b6353b0224f11868",
            "04a4b9e62cea4da19d71dd4a26f7d111"
          ]
        },
        "cellView": "form",
        "id": "vPm31hDNISu5",
        "outputId": "2fb5b24c-4311-4bdd-f404-79c9432f2fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… æ•¸æ“šæª”æ¡ˆè·¯å¾‘è¨­å®šç‚º: /content/drive/MyDrive/FRL_Slicing_Sim/kpi_traces_final_robust0.parquet\n",
            "âœ… å®¢æˆ¶ç«¯é…å°å·²æ›´æ–°ç‚º: ((1, 2), (3, 7), (5, 6))\n",
            "   - å®¢æˆ¶ç«¯0: BS 1 (eMBB) + BS 2 (URLLC)\n",
            "   - å®¢æˆ¶ç«¯1: BS 3 (eMBB) + BS 7 (URLLC)\n",
            "   - å®¢æˆ¶ç«¯2: BS 5 (eMBB) + BS 6 (URLLC)\n",
            "\n",
            "[æ•¸æ“šæº–å‚™] æ­£åœ¨ç‚º 3 å€‹çœŸå¯¦å®¢æˆ¶ç«¯æº–å‚™æ•¸æ“š...\n",
            "\n",
            "[DataManager] æ­£åœ¨å¾ /content/drive/MyDrive/FRL_Slicing_Sim/kpi_traces_final_robust0.parquet è®€å–æ•¸æ“š...\n",
            "\n",
            "==================== DataManager å•Ÿå‹•å‰é æª¢æŸ¥ ====================\n",
            "âœ… æ¸…ç†å¾Œçš„æ¬„ä½åˆ—è¡¨ (å…± 38 å€‹):\n",
            "   - ååé‡æ¬„ä½æˆåŠŸåŒ¹é…: 'throughput_dl_mbps'\n",
            "   - å»¶é²/ç·©è¡å€æ¬„ä½æˆåŠŸåŒ¹é…: 'buffer_occupancy_dl_bytes'\n",
            "   - å¯ç”¨BSç¯€é»: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
            "   - å®¢æˆ¶ç«¯BSé…å°é©—è­‰é€šé\n",
            "=================================================================\n",
            "\n",
            "[DataManager] æ­£åœ¨ç‚ºæ¯å€‹å®¢æˆ¶ç«¯ç”Ÿæˆæ•¸æ“šè»Œè·¡...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "è™•ç†å®¢æˆ¶ç«¯æ•¸æ“š:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fd1bc0440bd420e971b48da24159abd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   - å®¢æˆ¶ç«¯ 0: 10568 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 1: 6918 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 2: 8756 å€‹æ™‚é–“æ­¥\n",
            "\n",
            "[DataManager] æ•¸æ“šè™•ç†å®Œæˆï¼æˆåŠŸç‚º 3 / 3 å€‹å®¢æˆ¶ç«¯å‰µå»ºäº†ç’°å¢ƒã€‚\n",
            "âœ… 3 å€‹å®¢æˆ¶ç«¯çš„æ•¸æ“šè»Œè·¡å·²æº–å‚™å°±ç·’ã€‚\n",
            "ğŸ§ª æ¨¡å¼ 'Centralized' ä¸­ï¼Œç•°è³ªæ€§ã€å£“ç¸®ã€FedProx å°‡è¢«ç¦ç”¨ã€‚\n",
            "ğŸ›¡ï¸ æ¨¡å¼ 'Centralized' ä¸­ï¼Œå·®åˆ†éš±ç§å·²è¢«ç¦ç”¨ä»¥ä½œç‚ºééš±ç§åŸºæº–ã€‚\n",
            "\n",
            "========================= æº–å‚™åŸ·è¡Œå¯¦é©—: Centralized_run | Seed: 42 =========================\n",
            "\n",
            "[DataManager] æ­£åœ¨å¾ /content/drive/MyDrive/FRL_Slicing_Sim/kpi_traces_final_robust0.parquet è®€å–æ•¸æ“š...\n",
            "\n",
            "==================== DataManager å•Ÿå‹•å‰é æª¢æŸ¥ ====================\n",
            "âœ… æ¸…ç†å¾Œçš„æ¬„ä½åˆ—è¡¨ (å…± 38 å€‹):\n",
            "   - ååé‡æ¬„ä½æˆåŠŸåŒ¹é…: 'throughput_dl_mbps'\n",
            "   - å»¶é²/ç·©è¡å€æ¬„ä½æˆåŠŸåŒ¹é…: 'buffer_occupancy_dl_bytes'\n",
            "   - å¯ç”¨BSç¯€é»: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
            "   - å®¢æˆ¶ç«¯BSé…å°é©—è­‰é€šé\n",
            "=================================================================\n",
            "\n",
            "\n",
            "[ExperimentRunner] æ­£åœ¨åˆå§‹åŒ–å®¢æˆ¶ç«¯ç’°å¢ƒèˆ‡ä»£ç†...\n",
            "   - [é›†ä¸­å¼] å·²å°‡ 3 å€‹å®¢æˆ¶ç«¯çš„æ•¸æ“šåŒ¯é›†ï¼Œç¸½å…± 26242 å€‹æ™‚é–“æ­¥ã€‚\n",
            "[ExperimentRunner] åˆå§‹åŒ–å®Œæˆã€‚\n",
            "\n",
            "==================== ğŸƒâ€â™‚ï¸ é–‹å§‹åŸ·è¡Œå¯¦é©—: Centralized_run (Centralized) ====================\n",
            "\n",
            "[æ¨¡å¼] åŸ·è¡Œé›†ä¸­å¼è¨“ç·´ (Centralized)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Centralized Training:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac99e70413684afd922fdcc0ce9ed271"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 9: ğŸ“Š çµæœè¦–è¦ºåŒ–ï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "def load_all_results(base_output_dir):\n",
        "    all_evals, all_histories, all_privacies = [], [], []\n",
        "    config_data = None\n",
        "\n",
        "    if not os.path.exists(base_output_dir):\n",
        "        print(f\"âŒ æ‰¾ä¸åˆ°çµæœç›®éŒ„: {base_output_dir}\")\n",
        "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), None\n",
        "\n",
        "    # å…ˆå˜—è©¦åŠ è¼‰é…ç½®æ–‡ä»¶\n",
        "    config_files = glob.glob(os.path.join(base_output_dir, '**', '*_config.json'), recursive=True)\n",
        "    if config_files:\n",
        "        try:\n",
        "            with open(config_files[0], 'r') as f:\n",
        "                config_data = json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"ğŸŸ¡ è­¦å‘Š: è®€å–è¨­å®šæª”å¤±æ•—: {e}\")\n",
        "\n",
        "    for seed_folder in sorted(os.listdir(base_output_dir)):\n",
        "        if not seed_folder.startswith('seed_'): continue\n",
        "        try:\n",
        "            seed = int(seed_folder.split('_')[1])\n",
        "        except (ValueError, IndexError):\n",
        "            continue\n",
        "\n",
        "        for mode_folder in sorted(os.listdir(os.path.join(base_output_dir, seed_folder))):\n",
        "            exp_path = os.path.join(base_output_dir, seed_folder, mode_folder)\n",
        "            if not os.path.isdir(exp_path): continue\n",
        "\n",
        "            eval_files = glob.glob(os.path.join(exp_path, '*_evaluation_results.csv'))\n",
        "            history_files = glob.glob(os.path.join(exp_path, '*_training_history.csv'))\n",
        "            privacy_files = glob.glob(os.path.join(exp_path, '*_privacy_costs.csv'))\n",
        "\n",
        "            def read_and_append(file_list, data_list, mode_name, seed_val):\n",
        "                if not file_list: return\n",
        "                file_path = file_list[0]\n",
        "                try:\n",
        "                    if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
        "                        df = pd.read_csv(file_path)\n",
        "                        df['mode'] = mode_name\n",
        "                        df['seed'] = seed_val\n",
        "                        data_list.append(df)\n",
        "                except Exception as e:\n",
        "                    print(f\"ğŸŸ¡ è­¦å‘Š: è®€å–æª”æ¡ˆå¤±æ•—: {file_path}, {e}\")\n",
        "\n",
        "            read_and_append(eval_files, all_evals, mode_folder, seed)\n",
        "            read_and_append(history_files, all_histories, mode_folder, seed)\n",
        "            read_and_append(privacy_files, all_privacies, mode_folder, seed)\n",
        "\n",
        "    return (pd.concat(all_evals, ignore_index=True) if all_evals else pd.DataFrame()), \\\n",
        "           (pd.concat(all_histories, ignore_index=True) if all_histories else pd.DataFrame()), \\\n",
        "           (pd.concat(all_privacies, ignore_index=True) if all_privacies else pd.DataFrame()), \\\n",
        "           config_data\n",
        "\n",
        "# --- è¦–è¦ºåŒ–è¨­å®š ---\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
        "BASE_OUTPUT_DIR = \"/content/drive/MyDrive/FRL_Slicing_Sim/outputs_3clients_corrected\"\n",
        "FIGURES_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, \"figures\")\n",
        "os.makedirs(FIGURES_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "eval_df, history_df, privacy_df, loaded_config = load_all_results(BASE_OUTPUT_DIR)\n",
        "\n",
        "if eval_df.empty and history_df.empty:\n",
        "    print(\"âŒ æ‰¾ä¸åˆ°ä»»ä½•çµæœæª”æ¡ˆï¼Œç„¡æ³•ç¹ªåœ–ã€‚è«‹ç¢ºèª Cell 8 å·²æˆåŠŸåŸ·è¡Œä¸”è·¯å¾‘æ­£ç¢ºã€‚\")\n",
        "else:\n",
        "    SEEDS = [42, 2024, 888]\n",
        "    mode_order = [\"Isolated\", \"Centralized\", \"FedAvg\", \"FedProx\", \"ClusteredFL\"]\n",
        "\n",
        "    print(f\"âœ… æˆåŠŸè¼‰å…¥ {len(eval_df['seed'].unique()) if not eval_df.empty else 0} æ¬¡åŸ·è¡Œçš„çµæœã€‚\")\n",
        "\n",
        "    # --- åœ– 1: è¨“ç·´æ­·å²æ¯”è¼ƒ ---\n",
        "    if not history_df.empty:\n",
        "        plt.figure(figsize=(15, 8))\n",
        "        sns.lineplot(data=history_df, x='round', y='avg_reward', hue='mode',\n",
        "                     hue_order=mode_order, errorbar=('sd', 1), linewidth=2.5,\n",
        "                     err_style=\"band\", alpha=0.8)\n",
        "\n",
        "        plt.title('Training Performance Comparison (Corrected Version)', fontsize=18, weight='bold')\n",
        "        plt.xlabel('Communication Round / Equivalent Round', fontsize=14)\n",
        "        plt.ylabel('Average Episodic Reward', fontsize=14)\n",
        "        plt.legend(title='Training Mode', fontsize=12)\n",
        "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "        plt.xlim(0, 25)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'training_history_corrected.png'), dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    # --- åœ– 2: æœ€çµ‚æ€§èƒ½æ¯”è¼ƒ ---\n",
        "    if not eval_df.empty:\n",
        "        eval_to_plot = eval_df.rename(columns={'reward_pfl_finetuned': 'Final Reward Score'})\n",
        "\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        ax = sns.boxplot(data=eval_to_plot, x='mode', y='Final Reward Score',\n",
        "                         order=mode_order, palette=\"viridis\")\n",
        "\n",
        "        # æ·»åŠ ä¸­ä½æ•¸æ¨™è¨»\n",
        "        medians = eval_to_plot.groupby(['mode'])['Final Reward Score'].median().reindex(mode_order)\n",
        "        for xtick in ax.get_xticks():\n",
        "            if xtick < len(mode_order):\n",
        "                mode_name = mode_order[xtick]\n",
        "                median_val = medians.get(mode_name)\n",
        "                if pd.notna(median_val):\n",
        "                    ax.text(xtick, median_val + 5, f'Median: {median_val:.1f}',\n",
        "                            horizontalalignment='center', size='medium',\n",
        "                            color='black', weight='semibold',\n",
        "                            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
        "\n",
        "        plt.title('Final Performance Comparison (Corrected Client Configuration)', fontsize=18)\n",
        "        plt.xlabel('Experiment Mode', fontsize=14)\n",
        "        plt.ylabel('Final Reward Score', fontsize=14)\n",
        "        plt.xticks(rotation=15)\n",
        "\n",
        "        # çµ±è¨ˆæª¢é©—\n",
        "        groups = [eval_to_plot['Final Reward Score'][eval_to_plot['mode'] == m].dropna()\n",
        "                 for m in mode_order if m in eval_to_plot['mode'].unique()]\n",
        "        if len(groups) > 1:\n",
        "            h_stat, p_value = stats.kruskal(*groups)\n",
        "            plt.figtext(0.5, 0.01, f'Kruskal-Wallis Test: H = {h_stat:.2f}, p = {p_value:.4f}',\n",
        "                        ha='center', fontsize=12,\n",
        "                        bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 1])\n",
        "        plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'final_performance_corrected.png'), dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    # --- åœ– 3: å€‹äººåŒ–æ•ˆç›Šåˆ†æ ---\n",
        "    if not eval_df.empty:\n",
        "        first_seed = SEEDS[0]\n",
        "        cfl_eval = eval_df[(eval_df['mode'] == 'ClusteredFL') & (eval_df['seed'] == first_seed)]\n",
        "\n",
        "        if not cfl_eval.empty:\n",
        "            cfl_melted = cfl_eval.melt(\n",
        "                id_vars=['client_id'],\n",
        "                value_vars=['reward_global', 'reward_personalized', 'reward_pfl_finetuned'],\n",
        "                var_name='Model Type', value_name='Average Reward'\n",
        "            )\n",
        "\n",
        "            plt.figure(figsize=(14, 7))\n",
        "            sns.barplot(data=cfl_melted, x='client_id', y='Average Reward',\n",
        "                       hue='Model Type', palette='viridis')\n",
        "\n",
        "            plt.title(f'Personalization Benefits with Corrected BS Pairing (Seed={first_seed})', fontsize=16)\n",
        "            plt.xlabel('Client ID')\n",
        "            plt.ylabel('Average Reward')\n",
        "            plt.legend(title='Model Type')\n",
        "            plt.grid(axis='y', linestyle='--')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'personalization_benefit_corrected.png'), dpi=300)\n",
        "            plt.show()\n",
        "\n",
        "    # --- åœ– 4: éš±ç§æˆæœ¬è¿½è¹¤ ---\n",
        "    if not privacy_df.empty:\n",
        "        privacy_to_plot = privacy_df[privacy_df['mode'].isin(['FedAvg', 'FedProx', 'ClusteredFL'])]\n",
        "\n",
        "        if not privacy_to_plot.empty:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            sns.lineplot(data=privacy_to_plot, x='round', y='epsilon', hue='mode',\n",
        "                         errorbar=('sd', 1), linewidth=2.5)\n",
        "\n",
        "            # æ·»åŠ ç›®æ¨™epsilonç·š\n",
        "            if loaded_config and 'dp_target_epsilon' in loaded_config:\n",
        "                target_eps = loaded_config['dp_target_epsilon']\n",
        "                plt.axhline(y=target_eps, color='r', linestyle='--',\n",
        "                           label=f'Target Îµ = {target_eps}')\n",
        "\n",
        "            plt.title('Privacy Budget Consumption (Corrected DP Implementation)', fontsize=16)\n",
        "            plt.xlabel('Communication Round', fontsize=14)\n",
        "            plt.ylabel('Privacy Loss Îµ (Epsilon)', fontsize=14)\n",
        "            plt.legend()\n",
        "            plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'privacy_cost_corrected.png'), dpi=300)\n",
        "            plt.show()\n",
        "\n",
        "print(\"âœ… Cell 9: çµæœè¦–è¦ºåŒ–ï¼ˆä¿®æ­£ç‰ˆï¼‰å®Œæˆã€‚\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "izZVG_0CIV2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æ¥ä¸‹ä¾†\n",
        "* å·®åˆ†éš±ç§æ©Ÿåˆ¶å¯¦ç¾\n",
        "* æ“´å±•å®¢æˆ¶ç«¯æ•¸é‡ç ”ç©¶"
      ],
      "metadata": {
        "id": "JTjF-hQJwzzf"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9fd1bc0440bd420e971b48da24159abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74bfa31a20d0485db2c96fbffce6791b",
              "IPY_MODEL_d1ceaacdff6149dc9f7f3332399af84a",
              "IPY_MODEL_9286c52c3e9a410c81f852dab3cfc3df"
            ],
            "layout": "IPY_MODEL_0484c0f7ec694610869ad97d5067c400"
          }
        },
        "74bfa31a20d0485db2c96fbffce6791b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f4707264ba4b588836d0d81d208348",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_69097cc4b11f4ab2aa45df868fe69fde",
            "value": "è™•ç†å®¢æˆ¶ç«¯æ•¸æ“š:â€‡100%"
          }
        },
        "d1ceaacdff6149dc9f7f3332399af84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9bf2960e22c44d4a1ea7f929f3e0a25",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e2e81f76f4249d0a1176a04c2b8ff8e",
            "value": 3
          }
        },
        "9286c52c3e9a410c81f852dab3cfc3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a538e48ccb224dfba0757e507a05733e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eb485c8dd2614d55ba68141b13583f80",
            "value": "â€‡3/3â€‡[00:00&lt;00:00,â€‡â€‡3.31it/s]"
          }
        },
        "0484c0f7ec694610869ad97d5067c400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f4707264ba4b588836d0d81d208348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69097cc4b11f4ab2aa45df868fe69fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9bf2960e22c44d4a1ea7f929f3e0a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2e81f76f4249d0a1176a04c2b8ff8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a538e48ccb224dfba0757e507a05733e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb485c8dd2614d55ba68141b13583f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac99e70413684afd922fdcc0ce9ed271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46d3c6c877b74781a204cd7c3230c455",
              "IPY_MODEL_242c01b852674365a22585ea2f8d1fe0",
              "IPY_MODEL_487aa51627d3446485a0bf86353f83e1"
            ],
            "layout": "IPY_MODEL_50e8dabe97a84146a24e68f8e625318b"
          }
        },
        "46d3c6c877b74781a204cd7c3230c455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a92e5f432f463c988cb0d5b67afb8a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_714a9f3f7807411da5e735fab195fdca",
            "value": "Centralizedâ€‡Training:â€‡â€‡56%"
          }
        },
        "242c01b852674365a22585ea2f8d1fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70718e043a624243803fc9642268d1f9",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d66b0037c0245a6a513f75701e391cd",
            "value": 14
          }
        },
        "487aa51627d3446485a0bf86353f83e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28ad17cecbfe41b5b6353b0224f11868",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_04a4b9e62cea4da19d71dd4a26f7d111",
            "value": "â€‡14/25â€‡[07:50&lt;06:31,â€‡35.55s/it,â€‡loss=14835.8907,â€‡reward=288.78]"
          }
        },
        "50e8dabe97a84146a24e68f8e625318b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a92e5f432f463c988cb0d5b67afb8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714a9f3f7807411da5e735fab195fdca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70718e043a624243803fc9642268d1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d66b0037c0245a6a513f75701e391cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28ad17cecbfe41b5b6353b0224f11868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04a4b9e62cea4da19d71dd4a26f7d111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}